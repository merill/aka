{
  "link": "AA5cr2d",
  "title": "null",
  "autoCrawledTitle": "Introducing MASS â€“ A pre-training method that outperforms BERT and GPT in sequence to sequence language generation tasks - Microsoft Research",
  "keywords": "null",
  "category": "null",
  "url": "https://www.microsoft.com/en-us/research/blog/introducing-mass-a-pre-training-method-that-outperforms-bert-and-gpt-in-sequence-to-sequence-language-generation-tasks/?OCID=msr_blog_masspre_icml_tw"
}
